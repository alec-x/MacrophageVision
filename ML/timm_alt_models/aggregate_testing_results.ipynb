{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "architectures = ['efficientnet_b0', \n",
    "                 'efficientnet_b2', \n",
    "                 'inception_v4', \n",
    "                 'pnasnet5large', \n",
    "                 'resnext101_32x8d']\n",
    "\n",
    "arch_dirs = {}\n",
    "results_dir = r'../../output/train'\n",
    "dirs = os.listdir(results_dir)\n",
    "# Group directories in one group\n",
    "\n",
    "for arch in architectures:\n",
    "    arch_dirs[arch] = []\n",
    "    for dir in dirs:\n",
    "        if arch in dir:\n",
    "            arch_dirs[arch].append(os.path.join(results_dir, dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Max Test Accuracy\n",
    "Max test acccuracy in each fold of the 5 architectures tested. We take whichever epoch performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "arch_results = {}\n",
    "arch_best = {}\n",
    "for arch in architectures:\n",
    "    arch_results[arch] = []\n",
    "    arch_best[arch] = {}\n",
    "    best_acc = 0\n",
    "    for i, dir in enumerate(arch_dirs[arch]):\n",
    "        data = pd.read_csv(dir + r'/summary.csv')\n",
    "        curr_acc = max(data[\"eval_top1\"])\n",
    "        arch_results[arch].append(curr_acc)\n",
    "        if curr_acc > best_acc: \n",
    "            best_acc = curr_acc\n",
    "            arch_best[arch]['path'] = dir + r'/model_best.pth.tar'\n",
    "            arch_best[arch]['fold'] = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report max test accuracy of each fold and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for arch in architectures:\n",
    "    formatted_results = [ '%.2f' % result for result in arch_results[arch]]\n",
    "    formatted_average = '%.2f' % np.average(arch_results[arch])\n",
    "    formatted_fold = 'best fold %i' % arch_best[arch]['fold']\n",
    "    print(arch, formatted_results, formatted_average, formatted_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Extract Feature Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define calculation for extracting CD80 and CD206 levels from stains. Corrective techniques applied to remove image noise and variance between light levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def calculate_intensity(img, channel_num, diag=False):\n",
    "    arr = np.copy(img[channel_num])\n",
    "    avg1 = list(arr[:2,:].flatten())\n",
    "    avg2 = list(arr[:,:2].flatten())\n",
    "    avg3 = list(arr[-2:,:].flatten())\n",
    "    avg4 = list(arr[:,-2:].flatten())\n",
    "    avgs = avg1 + avg2 + avg3 + avg4\n",
    "    avgs.sort()\n",
    "    avg = avgs[int(len(avgs)*0.9)] # 70th percentile\n",
    "\n",
    "    \n",
    "    arr2 = np.copy(arr)\n",
    "    arr2 = arr2 - avg\n",
    "    arr2[arr2 < 0] = 0\n",
    "    arr2 = ndimage.median_filter(arr2, size=3)\n",
    "    num_non_zero = np.count_nonzero(arr2)\n",
    "    num_total = np.sum(arr2)\n",
    "    avg2 = num_total / num_non_zero\n",
    "    \n",
    "    lit_pct = num_non_zero/(96*96)*100\n",
    "\n",
    "    if diag:\n",
    "        print(\"average intensity of lit pixels: \", round(avg2,2))\n",
    "        print(\"percentage \\\"lit\\\": \", round(lit_pct, 2))\n",
    "        toshow = [arr, arr2]\n",
    "        labels = [\"Stain\", \"Clean Stain\"]\n",
    "        num_show = len(toshow)\n",
    "        f, axarr = plt.subplots(1,num_show, figsize=(8, 4))\n",
    "        for i in range(num_show):\n",
    "            axarr[i].imshow(toshow[i])\n",
    "            axarr[i].grid(False)\n",
    "            axarr[i].set_title(labels[i]) \n",
    "            axarr[i].get_xaxis().set_visible(False)\n",
    "            axarr[i].get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.show()\n",
    "    return avg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get CD80 and CD206 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fluor_marks_temp = {}\n",
    "fluor_paths = {\n",
    "    ('M0', r'../../data/processed/kerryn_dec/M0.pickle'),\n",
    "    ('M1', r'../../data/processed/kerryn_dec/M1.pickle'),\n",
    "    ('M2', r'../../data/processed/kerryn_dec/M2.pickle')\n",
    "}\n",
    "for ele in fluor_paths:\n",
    "    data = pickle.load(open(ele[1], 'rb'))\n",
    "    fluor_marks_temp[ele[0]] = data['images'][:,2:4,:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample order in each fold. This could be made cleaner by re-organizing everything from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "fluor_marks = {}\n",
    "for test_fold in range(1,6):\n",
    "    test_path = '../../data/processed/dataset_split/fold_%i/test' % test_fold\n",
    "    fluor_marks[test_fold] = {}\n",
    "    for pheno in ['M0', 'M1', 'M2']: # Clean this up later\n",
    "        fluor_marks[test_fold][pheno] = {}\n",
    "        curr_path = f'{test_path}/{pheno}'\n",
    "        (_, _, curr_files) = next(walk(curr_path))\n",
    "        curr_files = [int(file.rstrip('.png')) for file in curr_files]\n",
    "        for file_num in curr_files:\n",
    "            fluor_marks[test_fold][pheno][file_num] = fluor_marks_temp[pheno][file_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate CD80/CD206 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluorescent_stain = {}\n",
    "thresh = 8\n",
    "# 0 for CD80(blue), 1 for CD206(red), 2 for both (purple), 3 for neither (grey)\n",
    "\n",
    "# Need to get these results per fold then apply it to the fold tested\n",
    "for test_fold in range(1,6):\n",
    "    fluorescent_stain[test_fold] = {}\n",
    "\n",
    "    for pheno in ['M0', 'M1', 'M2']: # Clean this up later\n",
    "        fluorescent_stain[test_fold][pheno] = []\n",
    "\n",
    "        for sample_num in fluor_marks[test_fold][pheno]:\n",
    "            CD80_brightness = calculate_intensity(fluor_marks[test_fold][pheno][sample_num], 0)\n",
    "            CD206_brightness = calculate_intensity(fluor_marks[test_fold][pheno][sample_num], 1)\n",
    "            \n",
    "\n",
    "            cond_1 = CD80_brightness > thresh\n",
    "            cond_2 = CD206_brightness > thresh\n",
    "            if cond_1 and cond_2:\n",
    "                fluorescent_stain[test_fold][pheno].append(2)\n",
    "            elif cond_1:\n",
    "                fluorescent_stain[test_fold][pheno].append(0)\n",
    "            elif cond_2:\n",
    "                fluorescent_stain[test_fold][pheno].append(1)\n",
    "            else:\n",
    "                fluorescent_stain[test_fold][pheno].append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "import copy\n",
    "\n",
    "umap_results = {}\n",
    "for model_arch in architectures:    \n",
    "    print('Processing ' + model_arch)\n",
    "    model_path = arch_best[model_arch]['path']\n",
    "    test_fold = arch_best[model_arch]['fold']\n",
    "    test_path = '../../data/processed/dataset_split/fold_%i/test' % test_fold\n",
    "    num_classes = 3\n",
    "    model = create_model(\n",
    "        model_arch,\n",
    "        num_classes=num_classes,\n",
    "        in_chans=3,\n",
    "        pretrained=False,\n",
    "        checkpoint_path=model_path)\n",
    "    model = model.cuda()\n",
    "\n",
    "    loader = create_loader(\n",
    "        ImageDataset(test_path),\n",
    "        input_size=(3,96,96),\n",
    "        batch_size=1,\n",
    "        use_prefetcher=True,\n",
    "        interpolation='bicubic',\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225),\n",
    "        num_workers=1,\n",
    "        no_aug=True\n",
    "        )\n",
    "    model.eval()\n",
    "        \n",
    "    feature_maps = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input, target) in enumerate(loader):\n",
    "            input = input.cuda()\n",
    "            feature_maps.append(model.forward_features(input).cpu().numpy())\n",
    "            targets.append(target.cpu())\n",
    "\n",
    "    feature_maps = np.stack(feature_maps)\n",
    "    num_samples = feature_maps.shape[0] * feature_maps.shape[1]\n",
    "    features = feature_maps.shape[2:]\n",
    "    feature_maps = np.reshape(feature_maps, (num_samples,) + features)\n",
    "    feature_maps = np.reshape(feature_maps, (num_samples, reduce(mul, features)))\n",
    "    \n",
    "    targets = np.stack(targets)\n",
    "    targets = np.reshape(targets, (num_samples))\n",
    "\n",
    "    scaled_data = StandardScaler().fit_transform(feature_maps)\n",
    "    reducer = umap.UMAP(min_dist=0.3, n_neighbors=10)\n",
    "    umap_embedding = reducer.fit_transform(scaled_data)\n",
    "    df_umap = pd.DataFrame(umap_embedding,columns=['umap-one', 'umap-two'])\n",
    "    phenotypes = {0:\"M0\", 1:\"M1\", 2:\"M2\"}\n",
    "    df_umap['label'] = [phenotypes[int(ele)] for ele in targets]\n",
    "    \n",
    "    tmp = []\n",
    "    stain_temp = copy.deepcopy(fluorescent_stain)\n",
    "    for i, target in enumerate(targets):\n",
    "        tmp.append(stain_temp[test_fold][phenotypes[int(target)]].pop())\n",
    "\n",
    "    df_umap['fluor_mark'] = tmp\n",
    "    phenotype = {0: \"CD80+\",\n",
    "        1: \"CD206+\",\n",
    "        2: \"CD80+/CD206+\",\n",
    "        3: \"CD80-/CD206-\"}\n",
    "    df_umap['fluor_mark'] = [phenotype[int(ele)] for ele in df_umap['fluor_mark']] \n",
    "    umap_results[model_arch] = df_umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "num_archs = len(architectures)\n",
    "# fig, ax = plt.subplots(1, num_archs, figsize=(10*num_archs+5,10))\n",
    "\n",
    "\n",
    "for i, model_arch in enumerate(architectures):\n",
    "    fig, ax =plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "    colors = [\"#0a70c4\", \"#db0d0d\", \"#660ddb\", \"#b5b5b5\"]\n",
    "    customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "    sns.scatterplot(\n",
    "        x=\"umap-one\", y=\"umap-two\",\n",
    "        hue=\"fluor_mark\",\n",
    "        palette=customPalette,\n",
    "        data=umap_results[model_arch],\n",
    "        hue_order = ['CD80+', 'CD206+', 'CD80+/CD206+', 'CD80-/CD206-'],\n",
    "        legend=\"full\",\n",
    "        alpha=0.5,\n",
    "        ax=ax[0],\n",
    "    )\n",
    "    ax[0].set_title(\"Fluorescent Marker Phenotype\")\n",
    "    colors = [\"#b5b5b5\", \"#0a70c4\", \"#db0d0d\"]\n",
    "    customPalette = sns.set_palette(sns.color_palette(colors))         \n",
    "    sns.scatterplot(\n",
    "        x=\"umap-one\", y=\"umap-two\",\n",
    "        hue=\"label\",\n",
    "        data=umap_results[model_arch],\n",
    "        palette=customPalette,\n",
    "        hue_order = ['M0', 'M1', 'M2'],\n",
    "        legend=\"full\",\n",
    "        alpha=0.5,\n",
    "        ax=ax[1]\n",
    "    )\n",
    "    ax[1].set_title(\"UMAP for \" + model_arch)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01937c42ce6bae3e923241f624a509a1443d6ecfb36b65d653ce562a08a83eb9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
