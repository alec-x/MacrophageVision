{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Saliency Maps for 3-Way Macrophage/Monocyte Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to apply model interpretability algorithms from Captum library on a simple model and test samples from CIFAR dataset.\n",
    "\n",
    "In this tutorial we build a simple model as described in:\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n",
    "\n",
    "Then we use attribution algorithms such as `IntegratedGradients`, `Saliency`, `DeepLift` and `NoiseTunnel` to attribute the label of the image to the input pixels and visualize it.\n",
    "  \n",
    "  **Note:** Before running this tutorial, please install the torchvision, and matplotlib packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from captum.attr import DeepLift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './runs/mac_polar_run/test_data_fold_0'\n",
    "MODEL_PATH = './runs/mac_polar_run/model_fold_0'\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we load test and train datasets, define image transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    standardize_input()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = []\n",
    "raw_labels = []\n",
    "\n",
    "data = pickle.load(open(DATA_PATH, 'rb'))\n",
    "test_sampler = equal_classes_sampler(data.labels)\n",
    "testloader = DataLoader(data, batch_size=BATCH_SIZE, sampler=test_sampler,\n",
    "                        shuffle=False, num_workers=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, data in enumerate(testloader): \n",
    "    print(data[0].shape, data[1].shape)\n",
    "    img, label = data\n",
    "    if batch < 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using existing trained model\")\n",
    "net = torch.load(MODEL_PATH)\n",
    "net.to(\"cpu\")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we load some images from the test dataset and perform predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, transpose = True):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generic function that will be used for calling `attribute` on attribution algorithm defined in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_image_features(algorithm, input, target, **kwargs):\n",
    "    net.zero_grad()\n",
    "    tensor_attributions = algorithm.attribute(input,\n",
    "                                              target=target,\n",
    "                                              **kwargs\n",
    "                                             )\n",
    "    \n",
    "    return tensor_attributions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies DeepLift on test image. Deeplift assigns attributions to each input pixel by looking at the differences of output and its reference in terms of the differences of the input from the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images[:,0:2,:,:]\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[:,[0],:,:]))\n",
    "print('GroundTruth: ', ' '.join('%5s' % labels[j].item() for j in range(4)))\n",
    "\n",
    "outputs = net(images.float())\n",
    "predicted = torch.argmax(outputs,1).to(torch.double)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % predicted[j].item()\n",
    "                              for j in range(4)))\n",
    "                              \n",
    "num_imgs = len(images)\n",
    "\n",
    "dl = DeepLift(net)\n",
    "\n",
    "attr_dl = []\n",
    "org_imgs = []\n",
    "\n",
    "for i in range(num_imgs):\n",
    "    input = images[i].unsqueeze(0).float()\n",
    "    input.requires_grad = True\n",
    "    \n",
    "    attr_dl_tmp = attribute_image_features(dl, input, int(labels[i].item()), baselines=input * 0)\n",
    "    attr_dl_tmp = attr_dl_tmp.squeeze(0).cpu().detach().numpy()\n",
    "    attr_dl_tmp /= attr_dl_tmp.max()\n",
    "   # print(attr_dl_tmp.shape)\n",
    "    attr_dl.append(attr_dl_tmp) \n",
    "\n",
    "    org_img_tmp = np.transpose((images[i].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
    "    org_img_tmp /= org_img_tmp.max()\n",
    "    org_imgs.append(org_img_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we will visualize the attributions for `Saliency Maps`, `DeepLift`, `Integrated Gradients` and `Integrated Gradients with SmoothGrad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos = [\"M0\", \"M1\", \"M2\"]\n",
    "rows = 2\n",
    "cols = num_imgs\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*2.5 + .5, 5))\n",
    "\n",
    "for i in range(cols):\n",
    "    axes[0, i].set_axis_off()\n",
    "    axes[1, i].set_axis_off()\n",
    "    im1 = axes[0, i].imshow(org_imgs[i][:,:,0], cmap='viridis', vmin=0)\n",
    "    im2 = axes[1, i].imshow(attr_dl[i][0], cmap='viridis', vmin=0)\n",
    "    lbl = phenos[int(labels[i].item())]\n",
    "    prd = phenos[int(predicted[i].item())]\n",
    "    axes[0,i].set_title(f\"label: {lbl}\\npred: {prd}\")\n",
    "\n",
    "fig.subplots_adjust(bottom=0, top=0.8, left=0.1, right=0.8,\n",
    "                    wspace=0.05, hspace=0.02)\n",
    "\n",
    "# add an axes, lower left corner in [0.83, 0.1] measured in figure coordinate with axes width 0.02 and height 0.8\n",
    "cb_ax = fig.add_axes([0.83, 0.1, 0.02, 0.7])\n",
    "cbar = fig.colorbar(im1, cax=cb_ax)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aab8795380b30e625f05b9875eb19e47dede7d17a6e02ba200312899d03cb9f0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('torchenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
