{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Showcases integrated gradients on CIFAR10 dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial demonstrates how to apply model interpretability algorithms from Captum library on a simple model and test samples from CIFAR dataset.\r\n",
    "\r\n",
    "In this tutorial we build a simple model as described in:\r\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\r\n",
    "\r\n",
    "Then we use attribution algorithms such as `IntegratedGradients`, `Saliency`, `DeepLift` and `NoiseTunnel` to attribute the label of the image to the input pixels and visualize it.\r\n",
    "  \r\n",
    "  **Note:** Before running this tutorial, please install the torchvision, and matplotlib packages."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "from utils import *\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torchvision.transforms.functional as TF\r\n",
    "from torchvision import models\r\n",
    "#from torchvision.transforms import functional\r\n",
    "\r\n",
    "from captum.attr import IntegratedGradients\r\n",
    "from captum.attr import Saliency\r\n",
    "from captum.attr import DeepLift\r\n",
    "from captum.attr import NoiseTunnel\r\n",
    "from captum.attr import visualization as viz\r\n",
    "\r\n",
    "import random\r\n",
    "from MacDataset import MacDataset\r\n",
    "import macnet\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import statistics\r\n",
    "import traceback"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PATHS = [r\"..\\data\\processed\\alveolar.pickle\", \r\n",
    "         r\"..\\data\\processed\\marrow.pickle\",\r\n",
    "         r\"..\\data\\processed\\monocyte.pickle\"]\r\n",
    "BATCH_SIZE = 4\r\n",
    "NUM_WORKERS = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the cell below we load test and train datasets, define image transformers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "transforms = transforms.Compose([\r\n",
    "    standardize_input()\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_images = []\r\n",
    "raw_labels = []\r\n",
    "for i, path in enumerate(PATHS):\r\n",
    "    path_data = pickle.load(open(path, \"rb\"))\r\n",
    "    path_data[\"labels\"][:] = i\r\n",
    "    raw_images.append(path_data[\"images\"])\r\n",
    "    raw_labels.append(path_data[\"labels\"])\r\n",
    "\r\n",
    "images = np.vstack(raw_images)[:,[0],:,:]\r\n",
    "labels = np.hstack(raw_labels)\r\n",
    "\r\n",
    "fold_idx = list(range(len(labels)))\r\n",
    "random.shuffle(fold_idx)\r\n",
    "fold_idx = np.array_split(fold_idx, 5)\r\n",
    "min_len = len(labels)\r\n",
    "for fold in fold_idx:\r\n",
    "    if len(fold) < min_len:\r\n",
    "        min_len = len(fold)\r\n",
    "\r\n",
    "for i in range(len(fold_idx)):\r\n",
    "    if len(fold_idx[i]) > min_len:\r\n",
    "        fold_idx[i] = np.delete(fold_idx[i], 0)\r\n",
    "\r\n",
    "i = 0\r\n",
    "\r\n",
    "testing_images = images[fold_idx[i]]\r\n",
    "testing_labels = labels[fold_idx[i]]\r\n",
    "training_images = np.delete(images, fold_idx[i], axis=0)\r\n",
    "training_labels = np.delete(labels, fold_idx[i], axis=0)\r\n",
    "\r\n",
    "trainset = MacDataset(training_images, training_labels, \r\n",
    "                            transform=transforms)\r\n",
    "testset = MacDataset(testing_images, testing_labels,\r\n",
    "                            transform=transforms)\r\n",
    "\r\n",
    "train_sampler = equal_classes_sampler(trainset.labels)\r\n",
    "test_sampler = equal_classes_sampler(testset.labels)\r\n",
    "\r\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, sampler=train_sampler,\r\n",
    "                        shuffle=False, num_workers=0)\r\n",
    "\r\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, sampler=test_sampler,\r\n",
    "                        shuffle=False, num_workers=0) \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(trainloader)\r\n",
    "\r\n",
    "for batch, data in enumerate(trainloader): \r\n",
    "    print(data[0].shape, data[1].shape)\r\n",
    "    img, label = data\r\n",
    "    if batch < 2:\r\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Using existing trained model\")\r\n",
    "net = torch.load('./model')\r\n",
    "net.to(\"cpu\")\r\n",
    "net.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the cell below we load some images from the test dataset and perform predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "def imshow(img, transpose = True):\r\n",
    "    #img = img / 2 + 0.5     # unnormalize\r\n",
    "    npimg = img.numpy()\r\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "dataiter = iter(testloader)\r\n",
    "images, labels = dataiter.next()\r\n",
    "\r\n",
    "# print images\r\n",
    "imshow(torchvision.utils.make_grid(images))\r\n",
    "print('GroundTruth: ', ' '.join('%5s' % labels[j].item() for j in range(4)))\r\n",
    "\r\n",
    "outputs = net(images.float())\r\n",
    "predicted = torch.argmax(outputs,1).to(torch.double)\r\n",
    "\r\n",
    "print('Predicted: ', ' '.join('%5s' % predicted[j].item()\r\n",
    "                              for j in range(4)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's choose a test image at index `ind` and apply some of our attribution algorithms on it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ind = 3\r\n",
    "\r\n",
    "input = images[ind].unsqueeze(0).float()\r\n",
    "input.requires_grad = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A generic function that will be used for calling `attribute` on attribution algorithm defined in input."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def attribute_image_features(algorithm, input, **kwargs):\r\n",
    "    net.zero_grad()\r\n",
    "    tensor_attributions = algorithm.attribute(input,\r\n",
    "                                              target=int(labels[ind].item()),\r\n",
    "                                              **kwargs\r\n",
    "                                             )\r\n",
    "    \r\n",
    "    return tensor_attributions\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Computes gradients with respect to class `ind` and transposes them for visualization purposes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "saliency = Saliency(net)\r\n",
    "\r\n",
    "print(type(input), input.shape, type(labels[ind].item()))\r\n",
    "grads = saliency.attribute(input, target=int(labels[ind].item()))\r\n",
    "\r\n",
    "grads = grads.squeeze().cpu().detach().numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Applies integrated gradients attribution algorithm on test image. Integrated Gradients computes the integral of the gradients of the output prediction for the class index `ind` with respect to the input image pixels. More details about integrated gradients can be found in the original paper: https://arxiv.org/abs/1703.01365"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ig = IntegratedGradients(net)\r\n",
    "print(input.shape, (input.float() * 0).shape)\r\n",
    "attr_ig, delta = attribute_image_features(ig, input, baselines=input * 0, return_convergence_delta=True)\r\n",
    "attr_ig = attr_ig.squeeze(0).cpu().detach().numpy()\r\n",
    "attr_ig = attr_ig.squeeze(0)\r\n",
    "print('Approximation delta: ', abs(delta))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we demonstrate how to use integrated gradients and noise tunnel with smoothgrad square option on the test image. Noise tunnel with `smoothgrad square` option adds gaussian noise with a standard deviation of `stdevs=0.2` to the input image `nt_samples` times, computes the attributions for `nt_samples` images and returns the mean of the squared attributions across `nt_samples` images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ig = IntegratedGradients(net)\r\n",
    "nt = NoiseTunnel(ig)\r\n",
    "attr_ig_nt = attribute_image_features(nt, input, baselines=input * 0, nt_type='smoothgrad_sq',\r\n",
    "                                      nt_samples=10, stdevs=.5)\r\n",
    "attr_ig_nt = attr_ig_nt.squeeze(0).cpu().detach().numpy()\r\n",
    "attr_ig_nt = attr_ig_nt.squeeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Applies DeepLift on test image. Deeplift assigns attributions to each input pixel by looking at the differences of output and its reference in terms of the differences of the input from the reference."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dl = DeepLift(net)\r\n",
    "attr_dl = attribute_image_features(dl, input, baselines=input * 0)\r\n",
    "attr_dl = attr_dl.squeeze(0).cpu().detach().numpy()\r\n",
    "attr_dl = attr_dl.squeeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the cell below we will visualize the attributions for `Saliency Maps`, `DeepLift`, `Integrated Gradients` and `Integrated Gradients with SmoothGrad`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Original Image')\r\n",
    "print('Predicted:', predicted[ind], \r\n",
    "      ' Probability:', torch.max(F.softmax(outputs, 1)).item())\r\n",
    "\r\n",
    "original_image = np.transpose((images[ind].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\r\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\r\n",
    "plt.figure()\r\n",
    "#subplot(r,c) provide the no. of rows and columns\r\n",
    "f, axarr = plt.subplots(1,5) \r\n",
    "\r\n",
    "# use the created array to output your multiple images. In this case I have stacked 4 images vertically\r\n",
    "axarr[0].imshow(original_image)\r\n",
    "axarr[1].imshow(grads)\r\n",
    "axarr[2].imshow(attr_ig)\r\n",
    "axarr[3].imshow(attr_ig_nt)\r\n",
    "axarr[4].imshow(attr_dl)\r\n",
    "\r\n",
    "axarr[0].title.set_text(\"Original_image\")\r\n",
    "axarr[1].title.set_text(\"Overlayed Gradient Magnitudes\")\r\n",
    "axarr[2].title.set_text(\"Overlayed Integrated Gradients\")\r\n",
    "axarr[3].title.set_text(\"Overlayed Integrated Gradients \\n with SmoothGrad Squared\")\r\n",
    "axarr[4].title.set_text(\"Overlayed DeepLift\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "491765e01fa3dfc6c98fe3165a4d0b07724f880971dca49810d2604a1e334570"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('MacVis2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}