{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mac training Using Fluorescent and Brightfield Channels\r\n",
    "\r\n",
    "We train a predefined \"MacNet\" CNN to identify alveolar (tissue resident) macrophages versus bone marrow (proxy for monocyte-derived) macrophages. \r\n",
    "\r\n",
    "The input will be 1-4 channels of brightfield, lipid stain (BODIPY), nuclear stain (Hoechst), mitochondria stain (MitoTracker Red), or cell autofluorescence in green/red/blue channels.\r\n",
    "\r\n",
    "The output will be a binary classification of whether the cell is a bone marrow macrophage or alveolar macrophage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants/Variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# PATHS = [r\"D:\\data\\processed\\autof_3\\alveolar\", r\"D:\\data\\processed\\autof_3\\marrow\"]\r\n",
    "\r\n",
    "PATHS = [r\"..\\data\\processed\\alveolar.pickle\", \r\n",
    "         r\"..\\data\\processed\\marrow.pickle\",\r\n",
    "         r\"..\\data\\processed\\monocyte.pickle\"]\r\n",
    "NUM_FOLDS = 5\r\n",
    "NUM_BATCHES = 4 # num samples in batch\r\n",
    "NUM_EPOCHS = 15"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "from utils import *\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torchvision.transforms.functional as TF\r\n",
    "from torchvision import models\r\n",
    "#from torchvision.transforms import functional\r\n",
    "\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "import random\r\n",
    "from macdataset import MacDataset\r\n",
    "import macnet\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import statistics\r\n",
    "import traceback"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transforms\r\n",
    "This section defines the transforms used to augment the base data for training and testing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_transforms = transforms.Compose([\r\n",
    "    standardize_input(),\r\n",
    "    rotate_90_input()\r\n",
    "    ])\r\n",
    "test_transforms = transforms.Compose([\r\n",
    "    standardize_input()\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "raw_images = []\r\n",
    "raw_labels = []\r\n",
    "for i, path in enumerate(PATHS):\r\n",
    "    path_data = pickle.load(open(path, \"rb\"))\r\n",
    "    path_data[\"labels\"][:] = i\r\n",
    "    raw_images.append(path_data[\"images\"])\r\n",
    "    raw_labels.append(path_data[\"labels\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Balance \\# Images Per Class\r\n",
    "\r\n",
    "This balances the number of samples per class by randomly deleting samples till the classes are even. This seems to work better than the equal classes sampler\r\n",
    "\r\n",
    "It first detects the smallest class, then creates a random list of indices of which only the last min_len samples are kept. As this list is random, different samples should be selected each time.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "min_len = sum([len(label) for label in raw_labels])\r\n",
    "balanced_images = []\r\n",
    "balanced_labels = []\r\n",
    "for i in range(len(raw_labels)):\r\n",
    "    num_samples = len(raw_labels[i])\r\n",
    "    if  num_samples < min_len:\r\n",
    "        min_len = num_samples\r\n",
    "\r\n",
    "for i in range(len(raw_labels)):\r\n",
    "    num_samples = len(raw_labels[i])\r\n",
    "    raw_idx = list(range(num_samples))\r\n",
    "    random.shuffle(raw_idx)\r\n",
    "    raw_idx = raw_idx[:min_len]\r\n",
    "    balanced_images.append(raw_images[i][raw_idx])\r\n",
    "    balanced_labels.append(raw_labels[i][raw_idx])\r\n",
    "\r\n",
    "images = np.vstack(balanced_images)\r\n",
    "labels = np.hstack(balanced_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "fold_idx = list(range(len(labels)))\r\n",
    "random.shuffle(fold_idx)\r\n",
    "fold_idx = np.array_split(fold_idx, NUM_FOLDS)\r\n",
    "min_len = len(labels)\r\n",
    "for fold in fold_idx:\r\n",
    "    if len(fold) < min_len:\r\n",
    "        min_len = len(fold)\r\n",
    "\r\n",
    "for i in range(len(fold_idx)):\r\n",
    "    if len(fold_idx[i]) > min_len:\r\n",
    "        fold_idx[i] = np.delete(fold_idx[i], 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "i = 0\r\n",
    "testing_images = images[fold_idx[i]]\r\n",
    "training_images = np.delete(images, fold_idx[i], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, batches):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    total_done = 0\r\n",
    "    correct = 0\r\n",
    "    final_training_acc = 0\r\n",
    "    \r\n",
    "    for batch, data in enumerate(dataloader):\r\n",
    "        X, y = data[0][:,[0],:,:].to(device), data[1].to(device)\r\n",
    "        # Compute prediction error\r\n",
    "        pred = model(X.float())\r\n",
    "        loss = loss_fn(torch.squeeze(pred).flatten(), y.float())\r\n",
    "        # Backpropagation\r\n",
    "        model.train()\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        if batch % 25 == 0:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            correct += (torch.squeeze(pred).round() == y).type(torch.float).sum().item()\r\n",
    "            total_done += batches\r\n",
    "            training_acc = correct/total_done\r\n",
    "            final_training_acc = training_acc\r\n",
    "            #print(f\"Avg. Loss: {loss:>7f}, Accuracy: {training_acc:>.2%} [{current:>5d}/{size:>5d}]\", end=\"\\r\")\r\n",
    "    print(f\"Avg. Loss: {loss:>7f}, Accuracy: {final_training_acc:>.2%} [{size:>5d}/{size:>5d}]\")   \r\n",
    "    print()\r\n",
    "    return final_training_acc\r\n",
    "    \r\n",
    "\r\n",
    "def test(dataloader, model):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    model.eval()\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in dataloader:\r\n",
    "            X, y = data[0][:,[0],:,:].to(device), data[1].to(device)\r\n",
    "            pred = model(X.float())\r\n",
    "            test_loss += loss_fn(pred, torch.unsqueeze(y, 1).float()).item()\r\n",
    "            correct += (torch.squeeze(pred).round() == y).type(torch.float).sum().item()\r\n",
    "    test_loss /= size\r\n",
    "    correct /= size\r\n",
    "    print(f\"\\nTest Error: \\nAvg. Loss: {test_loss:>7f}, Accuracy: {correct:>0.2%}\\n\")\r\n",
    "    return correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "testing_errors = []\r\n",
    "training_errors = []\r\n",
    "for i in range(NUM_FOLDS):\r\n",
    "    print(\"\\n FOLD \" + str(i + 1) + \" OF \" + str(NUM_FOLDS))\r\n",
    "    print(\"=========================================================\\n\")\r\n",
    "    testing_images = images[fold_idx[i]]\r\n",
    "    testing_labels = labels[fold_idx[i]]\r\n",
    "    training_images = np.delete(images, fold_idx[i], axis=0)\r\n",
    "    training_labels = np.delete(labels, fold_idx[i], axis=0)\r\n",
    "\r\n",
    "    train_transforms = transforms.Compose([\r\n",
    "        standardize_input(),\r\n",
    "        rotate_90_input()\r\n",
    "        ])\r\n",
    "    test_transforms = transforms.Compose([\r\n",
    "        standardize_input()\r\n",
    "        ])\r\n",
    "    \r\n",
    "    train_data = MacDataset(training_images, training_labels, \r\n",
    "                                transform=train_transforms)\r\n",
    "    test_data = MacDataset(testing_images, testing_labels,\r\n",
    "                                transform=test_transforms)\r\n",
    "\r\n",
    "    train_sampler = equal_classes_sampler(train_data.labels)\r\n",
    "    test_sampler = equal_classes_sampler(test_data.labels)\r\n",
    "    \r\n",
    "    dataloader = DataLoader(train_data, batch_size=NUM_BATCHES, sampler=train_sampler,\r\n",
    "                            shuffle=False, num_workers=0)\r\n",
    "\r\n",
    "    dataloader_test = DataLoader(test_data, batch_size=NUM_BATCHES, sampler=test_sampler,\r\n",
    "                            shuffle=False, num_workers=0)              \r\n",
    "    # Get cpu or gpu device for training.\r\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "    print(\"Using {} device\".format(device))\r\n",
    "    \r\n",
    "    model = macnet.Net().to(device)\r\n",
    "\r\n",
    "    loss_fn = nn.CrossEntropyLoss()\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\r\n",
    "\r\n",
    "    print(\"\\nTraining Start\")\r\n",
    "\r\n",
    "    training_error = []\r\n",
    "    testing_error = []\r\n",
    "    for t in range(NUM_EPOCHS):\r\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "\r\n",
    "        print(\"\\nTraining Error:\")\r\n",
    "        training_error.append(train(dataloader, model, loss_fn, optimizer, NUM_BATCHES))\r\n",
    "        testing_error.append(test(dataloader_test, model))\r\n",
    "    training_errors.append(training_error[-1])\r\n",
    "    curr_testing_error = testing_error[-1]\r\n",
    "    if len(testing_errors) == 0 or curr_testing_error > max(testing_errors):\r\n",
    "        torch.save(model, \"./model\")\r\n",
    "    testing_errors.append(statistics.mean(testing_error))\r\n",
    "\r\n",
    "training_errors = [round(error, 4) for error in training_errors]\r\n",
    "testing_errors = [round(error, 4) for error in testing_errors]\r\n",
    "print(\"training errors per fold\")\r\n",
    "print(training_errors)\r\n",
    "print(\"testing errors per fold\")\r\n",
    "print(testing_errors)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " FOLD 1 OF 5\n",
      "=========================================================\n",
      "\n",
      "Using cuda device\n",
      "\n",
      "Training Start\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "\n",
      "Training Error:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([4])) that is different to the input size (torch.Size([12])) is deprecated. Please ensure they have the same size.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-59588e813d51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTraining Error:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mtraining_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_BATCHES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mtesting_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mtraining_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_error\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-38dface77283>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer, batches)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Compute prediction error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2751\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2753\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   2754\u001b[0m             \u001b[1;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2755\u001b[0m             \u001b[1;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([12])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aab8795380b30e625f05b9875eb19e47dede7d17a6e02ba200312899d03cb9f0"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('torchenv': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}