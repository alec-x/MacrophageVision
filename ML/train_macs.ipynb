{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mac training Using Fluorescent and Brightfield Channels\r\n",
    "\r\n",
    "We train a predefined \"MacNet\" CNN to identify alveolar (tissue resident) macrophages versus bone marrow (proxy for monocyte-derived) macrophages. \r\n",
    "\r\n",
    "The input will be 1-4 channels of brightfield, lipid stain (BODIPY), nuclear stain (Hoechst), mitochondria stain (MitoTracker Red), or cell autofluorescence in green/red/blue channels.\r\n",
    "\r\n",
    "The output will be a binary classification of whether the cell is a bone marrow macrophage or alveolar macrophage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"D:\\data\\processed\\autof_2\"\r\n",
    "NUM_FOLDS = 5\r\n",
    "NUM_BATCHES = 2\r\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torchvision.transforms.functional as TF\r\n",
    "from torchvision import models\r\n",
    "#from torchvision.transforms import functional\r\n",
    "\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "from captum.attr import IntegratedGradients\r\n",
    "from captum.attr import Saliency\r\n",
    "from captum.attr import DeepLift\r\n",
    "from captum.attr import NoiseTunnel\r\n",
    "from captum.attr import visualization as viz\r\n",
    "\r\n",
    "import random\r\n",
    "from macdataset import MacDataset\r\n",
    "import macnet\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal Class Sampler\r\n",
    "This function identifies different classes from the dataframe label column and returns a WeightedRandomSampler such that each class is sampled equally in aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_classes_sampler(df):\r\n",
    "    class_count = np.array((df[\"label\"].value_counts()))\r\n",
    "    weight = 1. / class_count\r\n",
    "    labels = list(df['label'])\r\n",
    "    weights = np.array([weight[label] for label in labels])\r\n",
    "    samples_weight = torch.from_numpy(weights).double()\r\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\r\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataloader, num_samples):\r\n",
    "    dataiter = iter(dataloader)\r\n",
    "    data = dataiter.next()\r\n",
    "    for _ in range(num_samples):\r\n",
    "        X = data[\"image\"][0][0]\r\n",
    "        plt.imshow(X)\r\n",
    "        plt.show()\r\n",
    "        input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\r\n",
    "This section defines the transforms used to augment the base data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class standardize_input(object):\r\n",
    "    # single channel\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, mean, std):\r\n",
    "        self.mean = mean\r\n",
    "        self.std = std\r\n",
    "    \"\"\"\r\n",
    "    def __call__(self, sample):\r\n",
    "        image, label = sample['image'], sample['label']\r\n",
    "        mean = np.mean(image)\r\n",
    "        stdev = np.std(image)\r\n",
    "        image = (image - mean)/stdev\r\n",
    "        return {'image': torch.from_numpy(image),\r\n",
    "                'label': label}\r\n",
    "class rotate_90_input(object):\r\n",
    "    def __call__(self, sample):\r\n",
    "        image, label = sample['image'], sample['label']\r\n",
    "        num_rot = random.randint(0, 3)\r\n",
    "        image = torch.rot90(image,num_rot, [1,2])\r\n",
    "        return {'image': image,\r\n",
    "                'label': label}    \r\n",
    "\r\n",
    "    def __repr__(self):\r\n",
    "        return self.__class__.__name__ + '(size={0})'.format(self.size)\r\n",
    "        \r\n",
    "class center_crop(object):\r\n",
    "    def __init__(self, size_range):\r\n",
    "        self.range = size_range\r\n",
    "    def __call__(self, sample):\r\n",
    "        image, label = sample['image'], sample['label']\r\n",
    "        orig = image.shape[2]\r\n",
    "        crop_size = random.randint(int(self.range[0]/2), int(self.range[1]/2))*2\r\n",
    "        p_size = int((orig - crop_size) / 2)\r\n",
    "        image = functional.center_crop(image, crop_size)\r\n",
    "        image = F.pad(input=image, pad=(p_size, p_size, p_size, p_size), mode='constant', value=0)\r\n",
    "        return {'image': image,\r\n",
    "                'label': label}\r\n",
    "\r\n",
    "train_transforms = transforms.Compose([\r\n",
    "    standardize_input(),\r\n",
    "    rotate_90_input()\r\n",
    "    ])\r\n",
    "test_transforms = transforms.Compose([\r\n",
    "    standardize_input()\r\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = PATH + '\\\\' + 'labels.csv' \r\n",
    "raw_data = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = np.array_split(raw_data.sample(frac=1), NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, batches):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    total_done = 0\r\n",
    "    correct = 0\r\n",
    "    bad_batches = 0\r\n",
    "    final_training_acc = 0\r\n",
    "    \r\n",
    "    for batch, data in enumerate(dataloader):\r\n",
    "        try:\r\n",
    "            X, y = data[\"image\"].to(device), data[\"label\"].to(device)\r\n",
    "\r\n",
    "            # Compute prediction error\r\n",
    "            pred = model(X.float())\r\n",
    "            loss = loss_fn(torch.squeeze(pred), y.float())\r\n",
    "\r\n",
    "            # Backpropagation\r\n",
    "            model.train()\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            if batch % 25 == 0:\r\n",
    "                loss, current = loss.item(), batch * len(X)\r\n",
    "                #print(torch.squeeze(pred).round(), y)\r\n",
    "                #input()\r\n",
    "                correct += (torch.squeeze(pred).round() == y).type(torch.float).sum().item()\r\n",
    "                total_done += batches\r\n",
    "                training_acc = correct/total_done\r\n",
    "                final_training_acc = training_acc\r\n",
    "                print(f\"Avg. Loss: {loss:>7f}, Accuracy: {training_acc:>.2%} [{current:>5d}/{size:>5d}]\", end=\"\\r\")\r\n",
    "        except:\r\n",
    "            bad_batches += 1\r\n",
    "    print()\r\n",
    "    print(\"bad batches:\" + str(bad_batches))\r\n",
    "    return final_training_acc\r\n",
    "    \r\n",
    "\r\n",
    "def test(dataloader, model):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    model.eval()\r\n",
    "    test_loss, correct, bad_batches = 0, 0, 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in dataloader:\r\n",
    "            try:\r\n",
    "                X, y = data[\"image\"].to(device), data[\"label\"].to(device)\r\n",
    "                pred = model(X.float())\r\n",
    "                test_loss += loss_fn(pred, torch.unsqueeze(y, 1).float()).item()\r\n",
    "                correct += (torch.squeeze(pred).round() == y).type(torch.float).sum().item()\r\n",
    "            except:\r\n",
    "                bad_batches += 1\r\n",
    "    test_loss /= size\r\n",
    "    correct /= size\r\n",
    "    print(f\"\\nTest Error: \\nAvg. Loss: {test_loss:>7f}, Accuracy: {correct:>0.2%}\\n\" \\\r\n",
    "        , \" bad_batches: \" + str(bad_batches))\r\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_errors = []\r\n",
    "training_errors = []\r\n",
    "for i in range(len(split_data)):\r\n",
    "    print(\"\\n FOLD \" + str(i + 1) + \" OF \" + str(NUM_FOLDS))\r\n",
    "    print(\"=========================================================\\n\")\r\n",
    "\r\n",
    "    train_idx = list(range(NUM_FOLDS))\r\n",
    "    train_idx.remove(i)\r\n",
    "    train_idx_start = train_idx.pop()\r\n",
    "    train_df = split_data[train_idx_start].copy()\r\n",
    "    for idx in train_idx:\r\n",
    "        train_df = train_df.append(split_data[idx])\r\n",
    "    \r\n",
    "    train_transforms = transforms.Compose([\r\n",
    "        standardize_input(),\r\n",
    "        rotate_90_input()\r\n",
    "        ])\r\n",
    "    test_transforms = transforms.Compose([\r\n",
    "        standardize_input()\r\n",
    "        ])\r\n",
    "\r\n",
    "    train_data = MacDataset(root_dir=PATH, dataframe=train_df,\r\n",
    "                                transform=train_transforms)\r\n",
    "    test_data = MacDataset(root_dir=PATH, dataframe=split_data[i],\r\n",
    "                                transform=test_transforms)\r\n",
    "\r\n",
    "    train_sampler = equal_classes_sampler(train_data.macs_frame)\r\n",
    "    test_sampler = equal_classes_sampler(test_data.macs_frame)\r\n",
    "    \r\n",
    "    dataloader = DataLoader(train_data, batch_size=NUM_BATCHES, sampler=train_sampler,\r\n",
    "                            shuffle=False, num_workers=0)\r\n",
    "\r\n",
    "    dataloader_test = DataLoader(test_data, batch_size=NUM_BATCHES, sampler=test_sampler,\r\n",
    "                            shuffle=False, num_workers=0)              \r\n",
    "\r\n",
    "    # Get cpu or gpu device for training.\r\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "    print(\"Using {} device\".format(device))\r\n",
    "    \r\n",
    "    model = macnet.Net().to(device)\r\n",
    "    #print(\"\\nConvolutional Neural Net Model:\")\r\n",
    "    #print(model)\r\n",
    "\r\n",
    "    loss_fn = nn.BCELoss()\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\r\n",
    "\r\n",
    "    print(\"\\nTraining Start\")\r\n",
    "\r\n",
    "    training_error = []\r\n",
    "    testing_error = []\r\n",
    "    for t in range(NUM_EPOCHS):\r\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "\r\n",
    "        print(\"\\nTraining Error:\")\r\n",
    "        training_error.append(train(dataloader, model, loss_fn, optimizer, NUM_BATCHES))\r\n",
    "        testing_error.append(test(dataloader_test, model))\r\n",
    "    training_errors.append(training_error[-1])\r\n",
    "    curr_testing_error = testing_error[-1]\r\n",
    "    if len(testing_errors) == 0 or curr_testing_error > max(testing_errors):\r\n",
    "        torch.save(model, \"./model\")\r\n",
    "    testing_errors.append(statistics.mean(testing_error))\r\n",
    "\r\n",
    "training_errors = [round(error, 4) for error in training_errors]\r\n",
    "testing_errors = [round(error, 4) for error in testing_errors]\r\n",
    "print(\"training errors per fold\")\r\n",
    "print(training_errors)\r\n",
    "print(\"testing errors per fold\")\r\n",
    "print(testing_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac3aead8dea22bd721698d41bf82f58dd98e26a479b82a1670803aba180e9c3b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}