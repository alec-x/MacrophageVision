{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mac training Using Fluorescent and Brightfield Channels\r\n",
    "\r\n",
    "We train a predefined \"MacNet\" CNN to identify alveolar (tissue resident) macrophages versus bone marrow (proxy for monocyte-derived) macrophages. \r\n",
    "\r\n",
    "The input will be 1-4 channels of brightfield, lipid stain (BODIPY), nuclear stain (Hoechst), mitochondria stain (MitoTracker Red), or cell autofluorescence in green/red/blue channels.\r\n",
    "\r\n",
    "The output will be a binary classification of whether the cell is a bone marrow macrophage or alveolar macrophage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS = [r\"D:\\data\\processed\\autof_3\\alveolar\", r\"D:\\data\\processed\\autof_3\\marrow\"]\r\n",
    "\r\n",
    "PATHS = [r\"..\\data\\processed\\alveolar.pickle\", r\"..\\data\\processed\\marrow.pickle\"]\r\n",
    "NUM_FOLDS = 5\r\n",
    "NUM_BATCHES = 4 # num samples in batch\r\n",
    "NUM_EPOCHS = 15"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "from utils import *\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torchvision.transforms.functional as TF\r\n",
    "from torchvision import models\r\n",
    "#from torchvision.transforms import functional\r\n",
    "\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "import random\r\n",
    "from macdataset import MacDataset\r\n",
    "import macnet\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import statistics\r\n",
    "import traceback"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transforms\r\n",
    "This section defines the transforms used to augment the base data for training and testing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_transforms = transforms.Compose([\r\n",
    "    standardize_input(),\r\n",
    "    rotate_90_input()\r\n",
    "    ])\r\n",
    "test_transforms = transforms.Compose([\r\n",
    "    standardize_input()\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_images = []\r\n",
    "raw_labels = []\r\n",
    "for i, path in enumerate(PATHS):\r\n",
    "    path_data = pickle.load(open(path, \"rb\"))\r\n",
    "    path_data[\"labels\"][:] = i\r\n",
    "    raw_images.append(path_data[\"images\"])\r\n",
    "    raw_labels.append(path_data[\"labels\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Balance \\# Images Per Class\r\n",
    "\r\n",
    "This balances the number of samples per class by randomly deleting samples till the classes are even. This seems to work better than the equal classes sampler\r\n",
    "\r\n",
    "It first detects the smallest class, then creates a random list of indices of which only the last min_len samples are kept. As this list is random, different samples should be selected each time.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min_len = sum([len(label) for label in raw_labels])\r\n",
    "balanced_images = []\r\n",
    "balanced_labels = []\r\n",
    "for i in range(len(raw_labels)):\r\n",
    "    num_samples = len(raw_labels[i])\r\n",
    "    if  num_samples < min_len:\r\n",
    "        min_len = num_samples\r\n",
    "\r\n",
    "for i in range(len(raw_labels)):\r\n",
    "    num_samples = len(raw_labels[i])\r\n",
    "    raw_idx = list(range(num_samples))\r\n",
    "    random.shuffle(raw_idx)\r\n",
    "    raw_idx = raw_idx[:min_len]\r\n",
    "    balanced_images.append(raw_images[i][raw_idx])\r\n",
    "    balanced_labels.append(raw_labels[i][raw_idx])\r\n",
    "\r\n",
    "images = np.vstack(balanced_images)\r\n",
    "labels = np.hstack(balanced_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fold_idx = list(range(len(labels)))\r\n",
    "random.shuffle(fold_idx)\r\n",
    "fold_idx = np.array_split(fold_idx, NUM_FOLDS)\r\n",
    "min_len = len(labels)\r\n",
    "for fold in fold_idx:\r\n",
    "    if len(fold) < min_len:\r\n",
    "        min_len = len(fold)\r\n",
    "\r\n",
    "for i in range(len(fold_idx)):\r\n",
    "    if len(fold_idx[i]) > min_len:\r\n",
    "        fold_idx[i] = np.delete(fold_idx[i], 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = 0\r\n",
    "testing_images = images[fold_idx[i]]\r\n",
    "training_images = np.delete(images, fold_idx[i], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, batches):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    total_done = 0\r\n",
    "    correct = 0\r\n",
    "    final_training_acc = 0\r\n",
    "    \r\n",
    "    for batch, data in enumerate(dataloader):\r\n",
    "        X, y = data[0][:,[0],:,:].to(device), data[1].to(device)\r\n",
    "        # Compute prediction error\r\n",
    "        pred = model(X.float())\r\n",
    "        loss = loss_fn(torch.squeeze(pred).flatten(), y.float())\r\n",
    "        # Backpropagation\r\n",
    "        model.train()\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        if batch % 25 == 0:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            correct += (torch.squeeze(pred).round() == y).type(torch.float).sum().item()\r\n",
    "            total_done += batches\r\n",
    "            training_acc = correct/total_done\r\n",
    "            final_training_acc = training_acc\r\n",
    "            #print(f\"Avg. Loss: {loss:>7f}, Accuracy: {training_acc:>.2%} [{current:>5d}/{size:>5d}]\", end=\"\\r\")\r\n",
    "    print(f\"Avg. Loss: {loss:>7f}, Accuracy: {final_training_acc:>.2%} [{size:>5d}/{size:>5d}]\")   \r\n",
    "    print()\r\n",
    "    return final_training_acc\r\n",
    "    \r\n",
    "\r\n",
    "def test(dataloader, model):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    model.eval()\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in dataloader:\r\n",
    "            X, y = data[0][:,[0],:,:].to(device), data[1].to(device)\r\n",
    "            pred = model(X.float())\r\n",
    "            test_loss += loss_fn(pred, torch.unsqueeze(y, 1).float()).item()\r\n",
    "            correct += (torch.squeeze(pred).round() == y).type(torch.float).sum().item()\r\n",
    "    test_loss /= size\r\n",
    "    correct /= size\r\n",
    "    print(f\"\\nTest Error: \\nAvg. Loss: {test_loss:>7f}, Accuracy: {correct:>0.2%}\\n\")\r\n",
    "    return correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_errors = []\r\n",
    "training_errors = []\r\n",
    "for i in range(NUM_FOLDS):\r\n",
    "    print(\"\\n FOLD \" + str(i + 1) + \" OF \" + str(NUM_FOLDS))\r\n",
    "    print(\"=========================================================\\n\")\r\n",
    "    testing_images = images[fold_idx[i]]\r\n",
    "    testing_labels = labels[fold_idx[i]]\r\n",
    "    training_images = np.delete(images, fold_idx[i], axis=0)\r\n",
    "    training_labels = np.delete(labels, fold_idx[i], axis=0)\r\n",
    "\r\n",
    "    train_transforms = transforms.Compose([\r\n",
    "        standardize_input(),\r\n",
    "        rotate_90_input()\r\n",
    "        ])\r\n",
    "    test_transforms = transforms.Compose([\r\n",
    "        standardize_input()\r\n",
    "        ])\r\n",
    "    \r\n",
    "    train_data = MacDataset(training_images, training_labels, \r\n",
    "                                transform=train_transforms)\r\n",
    "    test_data = MacDataset(testing_images, testing_labels,\r\n",
    "                                transform=test_transforms)\r\n",
    "\r\n",
    "    train_sampler = equal_classes_sampler(train_data.labels)\r\n",
    "    test_sampler = equal_classes_sampler(test_data.labels)\r\n",
    "    \r\n",
    "    dataloader = DataLoader(train_data, batch_size=NUM_BATCHES, sampler=train_sampler,\r\n",
    "                            shuffle=False, num_workers=0)\r\n",
    "\r\n",
    "    dataloader_test = DataLoader(test_data, batch_size=NUM_BATCHES, sampler=test_sampler,\r\n",
    "                            shuffle=False, num_workers=0)              \r\n",
    "    # Get cpu or gpu device for training.\r\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "    print(\"Using {} device\".format(device))\r\n",
    "    \r\n",
    "    model = macnet.Net().to(device)\r\n",
    "    #print(\"\\nConvolutional Neural Net Model:\")\r\n",
    "    #print(model)\r\n",
    "\r\n",
    "    loss_fn = nn.BCELoss()\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\r\n",
    "\r\n",
    "    print(\"\\nTraining Start\")\r\n",
    "\r\n",
    "    training_error = []\r\n",
    "    testing_error = []\r\n",
    "    for t in range(NUM_EPOCHS):\r\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "\r\n",
    "        print(\"\\nTraining Error:\")\r\n",
    "        training_error.append(train(dataloader, model, loss_fn, optimizer, NUM_BATCHES))\r\n",
    "        testing_error.append(test(dataloader_test, model))\r\n",
    "    training_errors.append(training_error[-1])\r\n",
    "    curr_testing_error = testing_error[-1]\r\n",
    "    if len(testing_errors) == 0 or curr_testing_error > max(testing_errors):\r\n",
    "        torch.save(model, \"./model\")\r\n",
    "    testing_errors.append(statistics.mean(testing_error))\r\n",
    "\r\n",
    "training_errors = [round(error, 4) for error in training_errors]\r\n",
    "testing_errors = [round(error, 4) for error in testing_errors]\r\n",
    "print(\"training errors per fold\")\r\n",
    "print(training_errors)\r\n",
    "print(\"testing errors per fold\")\r\n",
    "print(testing_errors)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aab8795380b30e625f05b9875eb19e47dede7d17a6e02ba200312899d03cb9f0"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('torchenv': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}