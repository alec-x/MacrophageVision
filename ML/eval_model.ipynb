{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Figure Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate plots from data recorded during training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Testing/Training Error Curve\n",
    "Plot the training of the first fold from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# https://stackoverflow.com/questions/14091387/creating-a-dictionary-from-a-csv-file\n",
    "testing_results = pickle.load(open('curr_run/model_test_results.p', \"rb\"))\n",
    "training_results = pickle.load(open('curr_run/model_train_hist.p', \"rb\"))\n",
    "\n",
    "print(len(training_results))\n",
    "\n",
    "\"\"\"\n",
    "result = {}\n",
    "for row in reader:\n",
    "    for column, value in row.items():  # consider .iteritems() for Python 2\n",
    "        result.setdefault(column, []).append(float(value))\n",
    "\n",
    "result[\"epoch\"] = [int(i) for i in result[\"epoch\"]]\n",
    "\n",
    "plt.plot(result[\"epoch\"], result[\"train_loss\"], result[\"test_loss\"])\n",
    "plt.title(\"Average Loss Per Epoch\")\n",
    "plt.legend([\"training\", \"testing\"])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(result[\"epoch\"], result[\"train_acc\"], result[\"test_acc\"])\n",
    "plt.ylim([0.6,1])\n",
    "plt.title(\"Average Accuracy Per Epoch\")\n",
    "plt.legend([\"training\", \"testing\"])\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Plotting\n",
    "\n",
    "https://stackoverflow.com/questions/53290306/confusion-matrix-and-test-accuracy-for-pytorch-transfer-learning-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"runs/tr_md_run/model_test_results.p\", \"rb\"))\n",
    "confusion_matrices = []\n",
    "matrices = []\n",
    "test_accuracies = []\n",
    "num_folds = len(data)\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    curr_data = list(zip(*data[fold]))\n",
    "    data[fold] = {}\n",
    "    data[fold][\"true\"] = curr_data[0]\n",
    "    data[fold][\"pred\"] = curr_data[1]\n",
    "\n",
    "    labels = data[fold][\"true\"]\n",
    "    labels = torch.flatten(torch.stack(labels))\n",
    "\n",
    "    outputs = data[fold][\"pred\"]\n",
    "    num_classes = len(outputs[0][0])\n",
    "    outputs = torch.flatten(torch.stack(outputs), end_dim=1)\n",
    "    outputs = torch.argmax(outputs, 1)\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    confusion_matrices.append(np.zeros((num_classes, num_classes))) \n",
    "\n",
    "    for t, p in zip(labels, outputs):\n",
    "            confusion_matrices[fold][int(t), int(p)] += 1\n",
    "\n",
    "    matrix = np.array(confusion_matrices[fold])\n",
    "    matrix = np.array([i/sum(i) for i in matrix])\n",
    "    matrices.append(matrix)\n",
    "\n",
    "    test_accuracy = 0\n",
    "    for i in range(num_classes):\n",
    "        test_accuracy += confusion_matrices[fold][i,i]\n",
    "    test_accuracy = test_accuracy / sum(confusion_matrices[fold].flatten())\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "for i, accuracy in enumerate(test_accuracies):\n",
    "    print(f\"Fold: {i}, Test Accuracy: {accuracy:>.2%}\")\n",
    "\n",
    "print(print(f\"Average: Test Accuracy: {sum(test_accuracies)/num_folds:>.2%}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "axis_labels = [\"M0\", \"M1\", \"M2\"]\n",
    "num_classes = len(axis_labels)\n",
    "matrix_sum = np.zeros_like(matrices[0])\n",
    "for mat in confusion_matrices:\n",
    "    matrix_sum += mat\n",
    "\n",
    "matrix_macnet = matrix_sum / len(matrices)\n",
    "\n",
    "matrix_df = pd.DataFrame(matrix_macnet, index=axis_labels, columns=axis_labels)\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(matrix_df, annot=True, fmt='.2%') # font size\n",
    "plt.title('Aggregate Results of 5-Fold Cross Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['TR', 'MD', 'Monocyte']\n",
    "archs = [\"macnet\", \"knn\", \"random forest\"]\n",
    "roc_data = []\n",
    "arch_matrices = {}\n",
    "arch_matrices[\"macnet\"] = matrix_sum\n",
    "arch_matrices[\"knn\"] = pickle.load(open(\"runs/tr_md_run/knn_conf_matrix.p\", \"rb\"))\n",
    "arch_matrices[\"random forest\"] = pickle.load(open(\"runs/tr_md_run/random_forest_conf_matrix.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for arch in archs:\n",
    "    matrix_count = arch_matrices[arch]\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for i, row in enumerate(matrix_count):\n",
    "        labels.append(np.ones(row.sum().astype(int))*i)\n",
    "        curr_preds = np.array([])\n",
    "        for j in range(len(row)):\n",
    "            tmp = np.ones(row[j].astype(int)).astype(int)*j\n",
    "            curr_preds = np.append(curr_preds, tmp)\n",
    "        preds.append(curr_preds)\n",
    "    labels = np.concatenate(labels)\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    res = classification_report(labels, preds, target_names=target_names, digits=4, output_dict=True)\n",
    "    print(arch)\n",
    "    del res[\"weighted avg\"][\"support\"]\n",
    "    for key in res[\"weighted avg\"].keys():\n",
    "        type_data = key\n",
    "        value = res[\"weighted avg\"][key]\n",
    "        roc_data.append([arch, type_data, value])\n",
    "        print(key, f\"{value:0.2%}    \", end=\"\")\n",
    "    roc_data.append([arch, \"accuracy\", res[\"accuracy\"]])\n",
    "    print(\"accuracy\", f\"{res['accuracy']:0.2%}    \", end=\"\")\n",
    "    print()\n",
    "\n",
    "\n",
    "roc_data = pd.DataFrame(roc_data, columns=[\"class\", \"data_type\", \"value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.set_theme(style=\"whitegrid\")\n",
    "\n",
    "yvals = np.arange(0,1,0.1)\n",
    "ylabels = [f'{i:.2%}' for i in yvals]\n",
    "sn.set(font_scale = 1.5)\n",
    "g = sn.catplot(\n",
    "    data=pd.DataFrame(roc_data), kind=\"bar\",\n",
    "    x=\"class\", y=\"value\", hue=\"data_type\",\n",
    "    ci=\"sd\", palette=\"dark\", height=5, aspect=2\n",
    ")\n",
    "g.set(yticks=yvals)\n",
    "g.set(yticklabels=ylabels)\n",
    "g.set(ylim=(0.5, 1))\n",
    "#g.set_yticklabels(ylabel)\n",
    "\n",
    "g.set_axis_labels(\"Class\", \"Percent\")\n",
    "g.legend.set_title(\"Metric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reciever Operator Characteristic Curve (ROC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "roc_data = pickle.load(open(\"model_roc_data.p\", \"rb\"))\n",
    "\n",
    "labels = roc_data[0][\"true\"]\n",
    "labels = torch.flatten(torch.stack(labels))\n",
    "labels_b = label_binarize(labels, classes=[0,1,2])\n",
    "\n",
    "outputs = roc_data[0][\"outputs\"]\n",
    "outputs = torch.flatten(torch.stack(outputs), end_dim=1)\n",
    "outputs = np.array(torch.softmax(outputs, 1))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(labels_b[:, i], outputs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(labels_b.ravel(), outputs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "         lw=lw, label='alveolar (area = %0.4f)' % roc_auc[0])\n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='marrow (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot(fpr[2], tpr[2], color='green',\n",
    "         lw=lw, label='monocyte (area = %0.4f)' % roc_auc[2])                  \n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.9, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic of 3-class CNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefining standardization operation used in training because cannot get transforms.Compose to work properly with Dataset object. TODO: Fixable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_input(image):\n",
    "    image = image.detach().numpy()\n",
    "    chans = range(image.shape[1])\n",
    "    means = [np.mean(image[0][chan]) for chan in chans]\n",
    "    stdevs = [np.std(image[0][chan]) for chan in chans]\n",
    "    for chan in chans:\n",
    "        image[0][chan] = (image[0][chan] - means[chan]) / stdevs[chan]\n",
    "    \n",
    "    output = torch.Tensor(image)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load testing data and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using existing trained model\")\n",
    "net = torch.load('./model_fold_0')\n",
    "net.to(\"cpu\")\n",
    "net.eval()\n",
    "\n",
    "test_data = pickle.load(open(\"./test_data_fold_0\", \"rb\"))\n",
    "test_sampler = equal_classes_sampler(test_data.labels)\n",
    "\n",
    "dataloader_test = DataLoader(test_data, batch_size=1, sampler=test_sampler,\n",
    "                        shuffle=False, num_workers=0)  \n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "net.fc3.register_forward_hook(get_activation('fc3'))               \n",
    "\n",
    "infer_results = pd.DataFrame(columns=['X', 'y', 'pred', 'activation'])\n",
    "\n",
    "for batch, data in enumerate(dataloader_test):\n",
    "    X, y = data[0].detach().clone(), data[1].detach().clone()\n",
    "    X = standardize_input(X)\n",
    "    pred = net(X[:,0:2,:,:].float())\n",
    "    pred_class = torch.argmax(pred,1).item()\n",
    "\n",
    "    X_out = data[0].detach().numpy()[0,:,:,:]\n",
    "    y_out = y.detach().numpy()\n",
    "    activation_out = np.array(activation['fc3'][0])\n",
    "    infer_results.loc[batch] = [X_out, y_out, pred_class, activation_out]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "TSNE = TSNE(n_components=2, perplexity=40, n_iter=10000, learning_rate=200)\n",
    "activations = np.stack(infer_results[\"activation\"].to_numpy())\n",
    "tsne_results = TSNE.fit_transform(activations)\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['t-sne-one', 't-sne-two'])\n",
    "infer_results.drop([\"activation\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def calculate_intensity(img, channel_num, diag=False):\n",
    "    arr = np.copy(img[channel_num])\n",
    "    avg1 = list(arr[:2,:].flatten())\n",
    "    avg2 = list(arr[:,:2].flatten())\n",
    "    avg3 = list(arr[-2:,:].flatten())\n",
    "    avg4 = list(arr[:,-2:].flatten())\n",
    "    avgs = avg1 + avg2 + avg3 + avg4\n",
    "    avgs.sort()\n",
    "    avg = avgs[int(len(avgs)*0.9)] # 70th percentile\n",
    "\n",
    "    \n",
    "    arr2 = np.copy(arr)\n",
    "    arr2 = arr2 - avg\n",
    "    arr2[arr2 < 0] = 0\n",
    "    arr2 = ndimage.median_filter(arr2, size=3)\n",
    "    num_non_zero = np.count_nonzero(arr2)\n",
    "    num_total = np.sum(arr2)\n",
    "    avg2 = num_total / num_non_zero\n",
    "    \n",
    "    lit_pct = num_non_zero/(96*96)*100\n",
    "\n",
    "    if diag:\n",
    "        print(\"average intensity of lit pixels: \", round(avg2,2))\n",
    "        print(\"percentage \\\"lit\\\": \", round(lit_pct, 2))\n",
    "        toshow = [arr, arr2]\n",
    "        labels = [\"Stain\", \"Clean Stain\"]\n",
    "        num_show = len(toshow)\n",
    "        f, axarr = plt.subplots(1,num_show, figsize=(8, 4))\n",
    "        for i in range(num_show):\n",
    "            axarr[i].imshow(toshow[i])\n",
    "            axarr[i].grid(False)\n",
    "            axarr[i].set_title(labels[i]) \n",
    "            axarr[i].get_xaxis().set_visible(False)\n",
    "            axarr[i].get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.show()\n",
    "    return avg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD80_brightnesses = []\n",
    "CD206_brightnesses = []\n",
    "\n",
    "marker_thresholds = [(7,7),(10,10),(12,12)]\n",
    "num_thresholds = len(marker_thresholds)\n",
    "# 0 for CD80(blue), 1 for CD206(red), 2 for both (purple), 3 for neither (grey)\n",
    "markers = [[] for _ in range(num_thresholds)]\n",
    "\n",
    "for i, row in infer_results.iterrows():\n",
    "    CD80_brightness = calculate_intensity(row[\"X\"], 2)\n",
    "    CD206_brightness = calculate_intensity(row[\"X\"], 3)\n",
    "    CD80_brightnesses.append(CD80_brightness)\n",
    "    CD206_brightnesses.append(CD206_brightness)\n",
    "\n",
    "    for j, threshold in enumerate(marker_thresholds):\n",
    "        cond_1 = CD80_brightness > threshold[0]\n",
    "        cond_2 = CD206_brightness > threshold[1]\n",
    "        if cond_1 and cond_2:\n",
    "            markers[j].append(2)\n",
    "        elif cond_1:\n",
    "            markers[j].append(0)\n",
    "        elif cond_2:\n",
    "            markers[j].append(1)\n",
    "        else:\n",
    "            markers[j].append(3)\n",
    "\n",
    "infer_results.drop([\"X\"], axis=1)\n",
    "\n",
    "infer_results[\"CD80_meas\"] = pd.Series(CD80_brightnesses)\n",
    "infer_results[\"CD206_meas\"] = pd.Series(CD206_brightnesses)\n",
    "for i, thresh in enumerate(marker_thresholds):\n",
    "    col_name = \"markers_\" + str(thresh)\n",
    "    infer_results[col_name] = pd.Series(markers[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_range = list(range(0,41,5))\n",
    "bin_range.extend([60,100])\n",
    "\n",
    "bin_switch = False\n",
    "\n",
    "if bin_switch:\n",
    "    print(infer_results[\"CD80_meas\"].value_counts(bins=bin_range).sort_index())\n",
    "    print(\"--------------------\")\n",
    "    print(infer_results[\"CD206_meas\"].value_counts(bins=bin_range).sort_index())\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "bins = list(range(0,71,5))\n",
    "plt.hist([infer_results[\"CD80_meas\"], infer_results[\"CD206_meas\"]], bins, label=[\"CD80\", \"CD206\"], color=['b', 'r'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.xticks(np.arange(0, 70, step=5))\n",
    "plt.title(\"Intensity Distribution of CD80/CD206\")\n",
    "plt.xlabel(\"Average pixel intensity\")\n",
    "plt.ylabel(\"Num Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,num_thresholds+1, figsize=(10*num_thresholds+10,10))\n",
    "\n",
    "\n",
    "for i, thresh in enumerate(marker_thresholds):\n",
    "    phenotype = {0: \"CD80+\",\n",
    "                1: \"CD206+\",\n",
    "                2: \"CD80+/CD206+\",\n",
    "                3: \"CD80-/CD206-\"}\n",
    "    col_name = \"markers_\" + str(thresh)\n",
    "    df_tsne['label'] = [phenotype[int(ele)] for ele in infer_results[col_name]] \n",
    "    colors = [\"#0a70c4\", \"#db0d0d\", \"#660ddb\", \"#b5b5b5\"]\n",
    "    customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "    sns.scatterplot(\n",
    "        x=\"t-sne-one\", y=\"t-sne-two\",\n",
    "        hue=\"label\",\n",
    "        palette=customPalette,\n",
    "        data=df_tsne,\n",
    "        hue_order = ['CD80+', 'CD206+', 'CD80+/CD206+', 'CD80-/CD206-'],\n",
    "        legend=\"full\",\n",
    "        alpha=0.5,\n",
    "        ax=ax[i],\n",
    "    )\n",
    "    ax[i].set_title(col_name)\n",
    "\n",
    "phenotype = {0: \"M0\",\n",
    "             1: \"M1\",\n",
    "             2: \"M2\"}\n",
    "df_tsne['label'] = [phenotype[int(ele)] for ele in infer_results['y']]              \n",
    "colors = [\"#ffc814\", \"#0a70c4\", \"#db0d0d\"]\n",
    "customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "sns.scatterplot(\n",
    "    x=\"t-sne-one\", y=\"t-sne-two\",\n",
    "    hue=\"label\",\n",
    "    palette=customPalette,\n",
    "    data=df_tsne,\n",
    "    hue_order = ['M0', 'M1', 'M2'],\n",
    "    legend=\"full\",\n",
    "    alpha=0.5,\n",
    "    ax=ax[num_thresholds],\n",
    ")\n",
    "ax=ax[num_thresholds].set_title(\"CNN Classification\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aab8795380b30e625f05b9875eb19e47dede7d17a6e02ba200312899d03cb9f0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('torchenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
